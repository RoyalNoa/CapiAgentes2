"""
Ruta: Backend/src/infrastructure/langgraph/nodes/assemble_node.py
Descripci칩n: Nodo de ensamblaje final para preparar respuestas coherentes
Estado: Activo
Autor/Responsable: migration-bot
칔ltima actualizaci칩n: 2025-01-14
Tareas relacionadas: T-007
Referencias: AI/Tablero/LangGraph/InfoAdicional.md#registro-de-avances
"""
from __future__ import annotations

from src.infrastructure.langgraph.nodes.base import GraphNode
from src.infrastructure.langgraph.state_schema import GraphState, StateMutator, WorkflowStatus
from src.core.logging import get_logger

logger = get_logger(__name__)


class AssembleNode(GraphNode):
    def __init__(self, name: str = "assemble") -> None:
        super().__init__(name=name)

    def run(self, state: GraphState) -> GraphState:
        logger.info({"event": "assemble_node_start", "node": self.name})

        # Ensure we have a response message
        response_message = state.response_message
        if not response_message:
            response_message = self._generate_fallback_response(state)

        # Finalize response data and metadata
        response_data = dict(state.response_data) if state.response_data else {}
        response_metadata = dict(state.response_metadata) if state.response_metadata else {}

        # Add assembly metadata
        response_metadata.update({
            "assembled_at": "assemble",
            "workflow_completed": True,
            "total_nodes": len(state.completed_nodes) + 1,  # +1 for current node
        })

        # Update state
        s = StateMutator.update_field(state, "current_node", self.name)
        s = StateMutator.update_field(s, "response_message", response_message)
        s = StateMutator.update_field(s, "response_data", response_data)
        s = StateMutator.update_field(s, "response_metadata", response_metadata)
        s = StateMutator.append_to_list(s, "completed_nodes", self.name)

        logger.info(
            {
                "event": "assemble_node_end",
                "response_length": len(response_message),
                "data_keys": list(response_data.keys()),
                "metadata_keys": list(response_metadata.keys()),
            }
        )

        return s

    def _generate_fallback_response(self, state: GraphState) -> str:
        """
        Generate fallback response when no other node provided one.

        Args:
            state: Current graph state

        Returns:
            Fallback response message
        """
        query = state.original_query or "consulta"

        # Check if we detected an intent
        if state.detected_intent:
            intent_name = getattr(state.detected_intent, "value", str(state.detected_intent))
            confidence = state.intent_confidence or 0.0

            if confidence < 0.3:
                return f"游뱂 No estoy seguro de c칩mo ayudarte con '{query}'. 쯇odr칤as ser m치s espec칤fico? Puedo ayudarte con res칰menes financieros, an치lisis de sucursales o detecci칩n de anomal칤as."
            else:
                return f"游늶 He procesado tu consulta sobre '{query}' (intenci칩n: {intent_name}), pero no pude generar una respuesta espec칤fica. 쯇odr칤as reformular la pregunta?"

        # Generic fallback
        return f"游뱄 He recibido tu consulta: '{query}'. Puedo ayudarte con an치lisis financieros, res칰menes de datos, detecci칩n de anomal칤as y an치lisis por sucursales. 쯈u칠 te gustar칤a hacer?"